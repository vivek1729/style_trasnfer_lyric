{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import cPickle as pkl\n",
    "import csv\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_multi_decoder = True\n",
    "if use_multi_decoder:\n",
    "    sys.path.append('/Users/vivekpradhan/Desktop/text_style_transfer/model/style_transfer/session_multi_decoder')\n",
    "else:\n",
    "    sys.path.append('/Users/vivekpradhan/Desktop/text_style_transfer/model/style_transfer/session_auto_encoder')\n",
    "\n",
    "#Import the relevant nmt module for that model    \n",
    "from nmt import (build_sampler, gen_sample, load_params,\n",
    "                 init_params, init_tparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define model directory and specific model\n",
    "options = None\n",
    "model_dir = '/Users/vivekpradhan/Documents/cs291-DL4NLP/models/'\n",
    "model = 'sen4_noadv_epoch20/'\n",
    "path = model_dir+model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#params = init_params(options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model = '/Users/vivekpradhan/Documents/cs291-DL4NLP/models/model_epoch20.npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load source dictionary and invert (Test code ....)\n",
    "dictionary = '/Users/vivekpradhan/Desktop/dict.pkl'\n",
    "with open(dictionary, 'rb') as f:\n",
    "    word_dict = pkl.load(f)\n",
    "word_idict = dict()\n",
    "for kk, vv in word_dict.iteritems():\n",
    "    word_idict[vv] = kk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<eos>'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_idict[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def saveWordEmb(model,op_f,output):\n",
    "    options = None\n",
    "    with open(op_f, 'rb') as f:\n",
    "        options = pkl.load(f)\n",
    "    params = init_params(options)\n",
    "    params = load_params(model, params)\n",
    "    print params['Wemb_encoder'].shape\n",
    "    word_emb = {}\n",
    "    for idx, val in enumerate(params['Wemb_encoder']):\n",
    "        word_emb[word_idict[idx]] = val\n",
    "    print \"Word embedding matrix is created!\"\n",
    "    print len(word_emb)\n",
    "    pkl.dump(word_emb, open( output, \"wb\" ))\n",
    "    print 'Saved input vocab to pickle file'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "op_f = path+'model_sen4_adv_epoch5.npz.pkl'\n",
    "model = path+'model_sen4_adv_epoch5.npz'\n",
    "output = path+'word_emb.pkl'\n",
    "options = None\n",
    "with open(op_f, 'rb') as f:\n",
    "    options = pkl.load(f)\n",
    "params = init_params(options)\n",
    "params = load_params(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Wemb_encoder',\n",
       " 'Wemb_dec',\n",
       " 'encoder_W',\n",
       " 'encoder_b',\n",
       " 'encoder_U',\n",
       " 'encoder_Wx',\n",
       " 'encoder_bx',\n",
       " 'encoder_Ux',\n",
       " 'ff_state_style0_W',\n",
       " 'ff_state_style0_b',\n",
       " 'ff_state_style1_W',\n",
       " 'ff_state_style1_b',\n",
       " 'style_matrix0',\n",
       " 'style_matrix1',\n",
       " 'decoder_style0_W',\n",
       " 'decoder_style0_b',\n",
       " 'decoder_style0_U',\n",
       " 'decoder_style0_Wx',\n",
       " 'decoder_style0_bx',\n",
       " 'decoder_style0_Ux',\n",
       " 'decoder_style0_Wc',\n",
       " 'decoder_style0_Wcx',\n",
       " 'ff_logit_lstm_style0_W',\n",
       " 'ff_logit_lstm_style0_b',\n",
       " 'ff_logit_prev_style0_W',\n",
       " 'ff_logit_prev_style0_b',\n",
       " 'ff_logit_ctx_style0_W',\n",
       " 'ff_logit_ctx_style0_b',\n",
       " 'ff_logit_style0_W',\n",
       " 'ff_logit_style0_b',\n",
       " 'decoder_style1_W',\n",
       " 'decoder_style1_b',\n",
       " 'decoder_style1_U',\n",
       " 'decoder_style1_Wx',\n",
       " 'decoder_style1_bx',\n",
       " 'decoder_style1_Ux',\n",
       " 'decoder_style1_Wc',\n",
       " 'decoder_style1_Wcx',\n",
       " 'ff_logit_lstm_style1_W',\n",
       " 'ff_logit_lstm_style1_b',\n",
       " 'ff_logit_prev_style1_W',\n",
       " 'ff_logit_prev_style1_b',\n",
       " 'ff_logit_ctx_style1_W',\n",
       " 'ff_logit_ctx_style1_b',\n",
       " 'ff_logit_style1_W',\n",
       " 'ff_logit_style1_b']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38607, 100)\n",
      "Word embedding matrix is created!\n",
      "38607\n",
      "Saved input vocab to pickle file\n"
     ]
    }
   ],
   "source": [
    "saveWordEmb(model,op_f,output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.04330294 -0.06614096 -0.04401691  0.31001216 -0.02090456 -0.00401442\n",
      "  0.43424031 -0.12378549  0.14554754  0.3538903  -0.15988322  0.08801933\n",
      " -0.06742784  0.26295337  0.18471742 -0.01111309  0.27061048  0.09083815\n",
      " -0.18784419  0.08431774  0.0315926  -0.10558893 -0.04643271  0.12524129\n",
      " -0.02426507  0.55463684 -0.24117975 -0.00347618 -0.00155025 -0.32300693\n",
      " -0.14667706 -0.28263214 -0.0031485   0.16893855 -0.22605506  0.49318746\n",
      "  0.35941678 -0.01608323 -0.05167737  0.08659404 -0.26098308 -0.10170592\n",
      "  0.2666778   0.14369166  0.11150087  0.1457357  -0.28043514 -0.12620161\n",
      "  0.03991625  0.05524464  0.16331375 -0.32258615 -0.06998368  0.04507739\n",
      " -0.03005157  0.22458848  0.13749908 -0.02095365  0.1639019   0.16348174\n",
      "  0.23343889  0.1371195   0.12426584 -0.02167365 -0.30254579 -0.00912012\n",
      " -0.08716342 -0.30563551  0.10814021  0.39904281  0.11924759  0.18444781\n",
      " -0.10517773 -0.0999231   0.075642   -0.01420997 -0.33320159 -0.09958635\n",
      " -0.02279624 -0.10658994 -0.47481295  0.03308642  0.01824712 -0.06389045\n",
      "  0.05843762  0.26607445  0.32868117  0.00471172  0.3471092  -0.00995656\n",
      " -0.12302574  0.24418789  0.0015663   0.17703408  0.26825699 -0.11796691\n",
      " -0.04635208 -0.02930345 -0.1297275  -0.0144918 ]\n"
     ]
    }
   ],
   "source": [
    "#Print out embedding for 'the', just a test that things work\n",
    "with open(path+'word_emb.pkl', 'rb') as f:\n",
    "        embed = pkl.load(f)\n",
    "        print embed['the']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This section generates comparative originality scores for different styles\n",
    "#Create test data now with stuff side by side\n",
    "with open(path+'q_test.txt') as f:\n",
    "    test_data = f.read().splitlines()\n",
    "with open(path+'s_test.txt') as f:\n",
    "    test_labels = f.read().splitlines()\n",
    "if use_multi_decoder:\n",
    "    with open(path+'q_test_style0.txt') as f:\n",
    "        country = f.read().splitlines()\n",
    "    with open(path+'q_test_style1.txt') as f:\n",
    "        rap = f.read().splitlines()\n",
    "else:\n",
    "    with open(path+'q_test.txt') as f:\n",
    "        country = f.read().splitlines()\n",
    "    rap = country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_file = open(path+'comp.tsv', 'w+')\n",
    "country_score = open(path+'q_test_style0_uniqueness.txt', 'w+')\n",
    "rap_score = open(path+'q_test_style1_uniqueness.txt', 'w+')\n",
    "tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
    "tsv_writer.writerow(['label', 'test', 'rap', 'uniq_score1', 'country', 'uniq_score2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(country)):\n",
    "    a = set(test_data[i].split())\n",
    "    b = set(rap[i].split())\n",
    "    c = set(country[i].split())\n",
    "    score_rap = 0\n",
    "    score_country = 0\n",
    "    if len(b) != 0:\n",
    "        score_rap = float(len(b-a))/len(b)\n",
    "    if len(c) != 0:\n",
    "        score_country = float(len(c-a))/len(c)\n",
    "    tsv_writer.writerow([test_labels[i],test_data[i],rap[i],score_rap,country[i],score_country])\n",
    "    country_score.write(str(score_country)+'\\n')\n",
    "    rap_score.write(str(score_rap)+'\\n')\n",
    "    \n",
    "out_file.close()\n",
    "country_score.close()\n",
    "rap_score.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Read uniqueness scores\n",
    "with open(path+'q_test_style0_uniqueness.txt') as f:\n",
    "    country_scores = f.read().splitlines()\n",
    "with open(path+'q_test_style1_uniqueness.txt') as f:\n",
    "    rap_scores = f.read().splitlines()\n",
    "if use_multi_decoder:\n",
    "    with open(path+'q_test_style0_semantics.txt') as f:\n",
    "        country_sem = f.read().splitlines()\n",
    "    with open(path+'q_test_style1_semantics.txt') as f:\n",
    "        rap_sem = f.readlines()\n",
    "    with open(path+'q_test_style0_classification.txt') as f:\n",
    "        country_class = f.read().splitlines()\n",
    "    with open(path+'q_test_style1_classification.txt') as f:\n",
    "        rap_class = f.read().splitlines()\n",
    "else:\n",
    "    with open(path+'q_test_style_semantics.txt') as f:\n",
    "        country_sem = f.read().splitlines()\n",
    "    with open(path+'q_test_style_classification.txt') as f:\n",
    "        country_class = f.read().splitlines()\n",
    "    rap_sem = country_sem\n",
    "    rap_class = country_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"when it 's up with your heart UNK love is cool UNK it 's like a new face UNK uh , you like the whole world UNK\""
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rap[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sen_rhyme(pred_verse):\n",
    "    sen_list = pred_verse.split('UNK')\n",
    "    #print sen_list\n",
    "    score = 0\n",
    "    if len(sen_list) < 2:\n",
    "        return 0\n",
    "    for sen in sen_list[1:]:\n",
    "        score = max(getrhymescore(get_phones(sen_list[0]),get_phones(sen)),score)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path+'q_train_1.txt') as f:\n",
    "    rap_train = f.read().splitlines()\n",
    "with open(path+'q_train_0.txt') as f:\n",
    "    country_train = f.read().splitlines()\n",
    "results = [0,0]\n",
    "for i in range(len(country)):\n",
    "    results[1] += get_sen_rhyme(rap_train[i])\n",
    "    results[0] += get_sen_rhyme(country_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.688138970697418, 0.6989392164992849]\n"
     ]
    }
   ],
   "source": [
    "results[0] = results[0]/len(country)\n",
    "results[1] = results[1]/len(country)\n",
    "print results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': {'sem': 0.9482538613094211, 'un': 0.6556689528019329, 'class': 0.9795534665099882, 'ry': 0.6680982820550564}, '0': {'sem': 0.9501921043439716, 'un': 0.6732123562540473, 'class': 0.4397179788484136, 'ry': 0.6820944607590453}}\n"
     ]
    }
   ],
   "source": [
    "#Generate output now\n",
    "results = {'0':{'class':0,'sem':0,'un':0,'ry':0},'1':{'class':0,'sem':0,'un':0,'ry':0}}\n",
    "count1 = 0\n",
    "count0 = 0\n",
    "for i in range(len(country)):\n",
    "    if test_labels[i] == '0':\n",
    "        #Input was country so I need to see the rap outcome\n",
    "        if float(rap_class[i]) >= 0.5:\n",
    "            results['1']['class'] += 1.0\n",
    "        results['1']['sem'] += float(rap_sem[i])\n",
    "        results['1']['un'] += float(rap_scores[i])\n",
    "        results['1']['ry'] += get_sen_rhyme(rap[i])\n",
    "        count1 += 1\n",
    "    elif test_labels[i] == '1':\n",
    "        #Input was country so I need to see the rap outcome\n",
    "        if float(country_class[i]) < 0.5:\n",
    "            results['0']['class'] += 1.0\n",
    "        results['0']['sem'] += float(country_sem[i])\n",
    "        results['0']['un'] += float(country_scores[i])\n",
    "        results['0']['ry'] += get_sen_rhyme(country[i])\n",
    "        count0 += 1\n",
    "\n",
    "results['0'].update((x, y/count0) for x, y in results['0'].items())   \n",
    "results['1'].update((x, y/count1) for x, y in results['1'].items())   \n",
    "print results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nDistribution of test inputs\\nrap inputs - 22996\\ncountry_outputs - 23004\\n\\nBaseline rhyming scores\\n[0.688138970697418, 0.6989392164992849] 0 -> country, 1 -> rap\\n'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Combined results initial setup\n",
    "\n",
    "multi_20 = {'1': {'sem': 0.9769881441335065, 'un': 0.16057578733121547, 'class': 0.29903495044340117}, '0': {'sem': 0.9515027617942285, 'un': 0.35594450120011906, 'class': 0.6145416594190294}}\n",
    "multi_5 = {'1': {'sem': 0.9384002097289246, 'un': 0.4419809004991422, 'class': 0.5007824726134585}, '0': {'sem': 0.9212599375060541, 'un': 0.5664992653402006, 'class': 0.8328404939989563}}\n",
    "baseline = {'1': {'sem': 0.9823626843348243, 'un': 0.0, 'class': 0.20932813829700425}, '0': {'sem': 0.9706052045298174, 'un': 0.0, 'class': 0.7364957524249636}}\n",
    "\n",
    "'''\n",
    "Distribution of test inputs\n",
    "rap inputs - 22996\n",
    "country_outputs - 23004\n",
    "\n",
    "Baseline rhyming scores\n",
    "[0.688138970697418, 0.6989392164992849] 0 -> country, 1 -> rap\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nSentence 1 epoch 15\\nWith adversary\\n{'1': {'sem': 0.6409812483698129, 'un': 0.384292847551575, 'class': 0.617628975462523}, '0': {'sem': 0.6538243811009465, 'un': 0.5030180109061819, 'class': 0.36727963780671846}}\\n\\nWithout adversary\\n{'1': {'sem': 0.6117844427160763, 'un': 0.3832387458287061, 'class': 0.6297579788720585}, '0': {'sem': 0.6230127219830662, 'un': 0.4959233139129372, 'class': 0.36806215415572074}}\\n\\nSentence 4 epoch 20\\nWith adversary\\n{'1': {'sem': 0.9436470064933412, 'un': 0.6658101641654034, 'class': 0.9668625146886016}, '0': {'sem': 0.9446442289678283, 'un': 0.6865281656585597, 'class': 0.4498237367802585}}\\n\\n\""
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Final results with correct data formats\n",
    "'''\n",
    "Sentence 1 epoch 15\n",
    "With adversary\n",
    "{'1': {'sem': 0.6409812483698129, 'un': 0.384292847551575, 'class': 0.617628975462523}, '0': {'sem': 0.6538243811009465, 'un': 0.5030180109061819, 'class': 0.36727963780671846}}\n",
    "\n",
    "Without adversary\n",
    "{'1': {'sem': 0.6117844427160763, 'un': 0.3832387458287061, 'class': 0.6297579788720585}, '0': {'sem': 0.6230127219830662, 'un': 0.4959233139129372, 'class': 0.36806215415572074}}\n",
    "\n",
    "Sentence 4 epoch 20\n",
    "With adversary\n",
    "{'1': {'sem': 0.9436470064933412, 'un': 0.6658101641654034, 'class': 0.9668625146886016, 'ry': 0.6669872506474298}, '0': {'sem': 0.9446442289678283, 'un': 0.6865281656585597, 'class': 0.4498237367802585, 'ry': 0.676318069490179}}\n",
    "\n",
    "Without adversary\n",
    "{'1': {'sem': 0.9482538613094211, 'un': 0.6556689528019329, 'class': 0.9795534665099882, 'ry': 0.6680982820550564}, '0': {'sem': 0.9501921043439716, 'un': 0.6732123562540473, 'class': 0.4397179788484136, 'ry': 0.6820944607590453}}\n",
    "\n",
    "Sentence 4 epoch 5\n",
    "With adversary\n",
    "{'1': {'sem': 0.9411942135842285, 'un': 0.6634244514851961, 'class': 0.9957696827262045, 'ry': 0.7047840251629705}, '0': {'sem': 0.9454477113462292, 'un': 0.6852487550519003, 'class': 0.5243243243243243, 'ry': 0.7193795884264967}}\n",
    "\n",
    "Without adversary\n",
    "{'1': {'sem': 0.9443355492688129, 'un': 0.6695312879649682, 'class': 0.9962397179788484, 'ry': 0.7073059104490426}, '0': {'sem': 0.9473732232960584, 'un': 0.691841732691024, 'class': 0.5490011750881316, 'ry': 0.7207903335792613}}\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[u'B', u'AA1', u'R', u'B', u'AH0', u'L', u'Z']]\n",
      "[[u'B', u'AA1', u'R', u'B', u'IH0', u'K', u'Y', u'UW2']]\n",
      "[[u'B', u'AA1', u'R', u'B', u'IH0', u'K', u'Y', u'UW2', u'D']]\n",
      "[[u'B', u'AA1', u'R', u'B', u'IH0', u'K', u'Y', u'UW2', u'IH0', u'NG']]\n",
      "[[u'B', u'AA1', u'R', u'B', u'IH0', u'K', u'Y', u'UW2', u'Z']]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "arpabet = nltk.corpus.cmudict.dict()\n",
    "for word in ('barbels', 'barbeque', 'barbequed', 'barbequeing', 'barbeques'):\n",
    "    print(arpabet[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_phones(sen):\n",
    "    words = sen.lower().split(' ')\n",
    "    phon_sen = []\n",
    "    for word in words:\n",
    "        try:\n",
    "            x = arpabet[word]\n",
    "            phons = filter(lambda item: str(item).startswith(('A','E','I','O','U','Y')),x[0])\n",
    "            phon_str = (' ').join(phons)\n",
    "            phon_sen.append(phon_str)\n",
    "        except Exception as er:\n",
    "            #print er\n",
    "            continue\n",
    "    #print phon_sen\n",
    "    return phon_sen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'AY1', u'AY1', u'AO1', u'AY1', u'IY1', u'AW1 ER0']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sen = 'I fight for my meals bouncer'\n",
    "get_phones(test_sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = [u'B', u'AA1', u'R', u'B', u'AH0', u'L', u'Z']\n",
    "phons = filter(lambda item: str(item).startswith(('A','E','I','O','U','Y')),x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get rhyme score now given two sequence of phonemes\n",
    "def getrhymescore(phon1,phon2):\n",
    "    min_diff = 50\n",
    "    l1 = len(phon1)\n",
    "    l2 = len(phon2)\n",
    "    den = max(l1,l2)\n",
    "    score = 0\n",
    "    for i in range(len(phon1)):\n",
    "        x1 = float(i+1)\n",
    "        x2 = 0.0\n",
    "        min_diff = 50\n",
    "        for j in range(len(phon2)):\n",
    "            if phon2[j].endswith(phon1[i]):\n",
    "                if min_diff > abs(j-i):\n",
    "                    min_diff = abs(j-i)\n",
    "                    x2 = float(j+1)\n",
    "        #compute score for phon1[i]\n",
    "        score += (den - abs(x2-x1))/den\n",
    "        #print \"score for i\",i,x1,x2,score\n",
    "    if (l1 > 0):\n",
    "        return score/l1 #Return the average score for all words in phon1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen1 = 'i dont need to fight'\n",
    "sen2 = 'i dont need to fight'\n",
    "getrhymescore(get_phones(sen1),get_phones(sen2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
